{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3pIaGLskZDC"
      },
      "source": [
        "# Classification system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRtqtcm6kgWg"
      },
      "source": [
        "This notebook allows to do predictions using all the trained models (Virulence, Promiscuity and Resistance). The input needed is a list of sequences to be analyzed, and the output will be the predicted class for each of the sequences. The output will be both printed in the notebook itself and downloaded in a csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrFJHbXZmUf3"
      },
      "source": [
        "## **Import Necessary Modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J10ibRwlfF2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d86482-fd51-4908-9478-dab8c5f6ff0a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xHaJOgewVtu",
        "outputId": "611daddf-cc47-4554-ab0c-2e983381ef89"
      },
      "source": [
        "pip install biopython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5MRMJz1gkN2"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.utils import np_utils\n",
        "from random import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Embedding, LSTM\n",
        "from keras import regularizers, layers, preprocessing\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from Bio.Seq import Seq\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3xpRPNxkSUK"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h573ExLxr2ZB"
      },
      "source": [
        "The following cells predict the class for each of the input sequences. Some results are shown here, although further details about them can be found in the 'Result' section of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cZgmyWtnR-Q"
      },
      "source": [
        "Dataframe=pd.read_csv('ADD THE PATH FOR THE CSV WITH THE SEQUENCES TO BE STUDIED') # Add your here for the input sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFfcxS-ygnDY"
      },
      "source": [
        "#Process of conversion from aminoacid sequence to codon sequence\n",
        "Datacodons = Dataframe.copy()\n",
        "\n",
        "Codons = list(Datacodons['genes'])\n",
        "\n",
        "\n",
        "length = []\n",
        "for n in range(len(Codons)):\n",
        "    Codons[n] = list([Codons[n][i:i+3] for i in range(0, len(Codons[n]), 3)])\n",
        "    length.append(len(Codons[n]))\n",
        "    \n",
        "Datacodons['codons'] = Codons\n",
        "\n",
        "#The maximum length will be used for the padding of sequences\n",
        "maxlen = max(length) # cut off after this number of codons in a list\n",
        "\n",
        "max_words = 64 # Number of words in the dictionary, equal to the number of  possible codons\n",
        "max_features = max_words\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(list(DataCod['codons']))\n",
        "sequences = tokenizer.texts_to_sequences(list(DataCod['codons']))\n",
        "word_index = tokenizer.word_index\n",
        "Xpad = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post', value=0)\n",
        "\n",
        "gene_decoded=[]\n",
        "for i in Xpad:\n",
        "  gene=''\n",
        "  for k in i:\n",
        "    if k !=0:\n",
        "      gene=gene+(list(word_index.keys())[list(word_index.values()).index(k)])\n",
        "  gene_decoded.append(gene)\n",
        "\n",
        "# This step ensures that the generated dictionary has exactly what we asked for since in some cases words that are not codons are generated\n",
        "new_dict= {'cac', 'cgt', 'aat', 'atg', 'tac', 'att', 'tgg', 'gac', 'tgc', 'act', 'gtt', 'gaa', 'aaa', 'cag', 'tga', 'ttg', 'gct', 'ttc', 'tct', 'ggc', 'aca', 'taa', 'ctg', 'ata', 'caa', 'ctt', 'tcg', 'gtc', 'aac', 'gga', 'acg', 'gca', 'tta', 'cta', 'acc', 'gat', 'tca', 'tat', 'agg', 'tgt', 'gtg', 'cga', 'cgc', 'ttt', 'aga', 'ggt', 'ctc', 'cca', 'ccg', 'gcg', 'tag', 'atc', 'cat', 'agt', 'cgg', 'aag', 'gag', 'cct', 'gta', 'ggg', 'tcc', 'agc', 'ccc', 'gcc'}\n",
        "unwanted= set(word_index) - set(new_dict)\n",
        "for unwanted_key in unwanted: del word_index[unwanted_key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnGRpQusWbUA"
      },
      "source": [
        "main_model = keras.models.load_model('ADD THE PATH HERE FOR THE TRAINED MAIN DISCRIMINATOR MODEL') # Add here the path for the main discriminator model. We provided a trained model in the repository.\n",
        "\n",
        "prediction = main_model.predict(Xpad)   # Prediction goes as [None,Promiscuity,Resistance,Virulence]\n",
        "\n",
        "Preds = prediction.copy()\n",
        "# Important! Transform the probabilities to binary decisions (either you belong to a label or not), we used the typical treshold in literature of 0.5\n",
        "Preds[ np.where( Preds >= 0.5 ) ] = 1\n",
        "Preds[ np.where( Preds < 0.5 ) ] = 0\n",
        "\n",
        "\n",
        "# We'll store in different lists the sequences depending on the prediction given\n",
        "# This will be the input of the following models, which will give a further \n",
        "# description of the sequences.\n",
        "resistance = []\n",
        "virulence = []\n",
        "promiscuity = []\n",
        "nodanger = []\n",
        "for i in range(len(Preds)):\n",
        "  if Preds[i][2] == 1:\n",
        "    virulence.append(Xpad[i])\n",
        "  if Preds[i][1] == 1:\n",
        "    resistance.append(Xpad[i])\n",
        "  if Preds[i][0] == 1:\n",
        "    promiscuity.append(Xpad[i])\n",
        "  if Preds[i][0]== 0 and Preds[i][1]== 0 and Preds[i][2]== 0:\n",
        "    nodanger.append(Xpad[i])\n",
        "\n",
        "print('Number of resistance sequences found: ' + str(len(resistance)))\n",
        "print('Number of virulence sequences found: ' + str(len(virulence)))\n",
        "print('Number of promiscuity sequences found: ' + str(len(promiscuity)))\n",
        "print('Number of missclass sequences found: ' + str(len(nodanger)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JMm87QhnEtR"
      },
      "source": [
        "# We define the dictionary describing each of the antibiotic resistance mechanisms\n",
        "dd = {\n",
        "    'Aminoglycosides': ['phosphorylation', 'acetylation', 'nucleotidylation', 'efflux', 'altered target'],\n",
        "    'betalactams': ['hydrolysis', 'efflux', 'altered target'],\n",
        "    'Glycopeptides': ['reprogramming peptidoglycan biosynthesis'],\n",
        "    'Rifampin': ['ADP-ribosylation', 'efflux', 'altered target'],\n",
        "    'MLS': ['hydrolysis', 'phosphorylation', 'nucleotidylation','acetylation','efflux', 'altered target'],\n",
        "    'Tetracyclines': ['monooxygenation', 'efflux', 'altered target'],\n",
        "    'Sulfonamides': ['efflux','altered target'],\n",
        "    'Lipopeptides' : ['altered target'],\n",
        "    'Phenicol' : ['acetylation', 'efflux', 'altered target'],\n",
        "}\n",
        "dd_s=dd.copy()\n",
        "for key in dd_s:\n",
        "  dd_s[key].sort()\n",
        "\n",
        "# Here we will only predict the sequences that are classified as 'Resistance' in the main discriminator.\n",
        "\n",
        "if len(resistance)!=0:\n",
        "  # We modify the padding to 1395, which is the maximum length for the sequences used to train the model\n",
        "  resistance_pad = pad_sequences(np.asarray(resistance), maxlen=1395, padding='post', truncating='post', value=0)\n",
        "  \n",
        "  resistant_model = keras.models.load_model('ADD THE PATH HERE FOR THE TRAINED RESISTANCE MODEL') # Add here the path for the resistance model. We provided a trained model in the repository.\n",
        "  \n",
        "  decoded=[]\n",
        "  antibiotic=[]\n",
        "  ambiguo=[]\n",
        "  prediction = resistant_model.predict(resistance_pad)  \n",
        "  Preds = prediction.copy()\n",
        "  Preds[ np.where( Preds >= 0.5 ) ] = 1\n",
        "  Preds[ np.where( Preds < 0.5 ) ] = 0\n",
        "  for i in range(len(Preds)):\n",
        "    vector=[]\n",
        "    if Preds[i][0]==1:\n",
        "      vector.append('ADP-ribosylation')\n",
        "    if Preds[i][1]==1:\n",
        "      vector.append('acetylation')\n",
        "    if Preds[i][2]==1:\n",
        "      vector.append('altered target')\n",
        "    if Preds[i][3]==1:\n",
        "      vector.append('efflux')\n",
        "    if Preds[i][4]==1:\n",
        "      vector.append('hydrolysis')\n",
        "    if Preds[i][5]==1:\n",
        "      vector.append('monooxygenation')\n",
        "    if Preds[i][6]==1:\n",
        "      vector.append('nucleotidylation')\n",
        "    if Preds[i][7]==1:\n",
        "      vector.append('phosphorylation')\n",
        "    if Preds[i][8]==1:\n",
        "      vector.append('reprogramming peptidoglycan biosynthesis')\n",
        "    decoded.append(vector)\n",
        "\n",
        "  for vec in decoded:\n",
        "    try:\n",
        "      antibiotic.append(list(dd_s.keys())[list(dd_s.values()).index(list(vec))])\n",
        "    except ValueError:\n",
        "      ambiguo.append(vec)\n",
        "\n",
        "  print('\\n----------------------------------------------------------------')\n",
        "  print('Results ready in \"Results\" tab')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1ktA1RSv_Yc"
      },
      "source": [
        "  main={}\n",
        "  for i in range(len(antibiotic)):\n",
        "    unique, counts = np.unique(antibiotic[i], return_counts=True)\n",
        "    dic=dict(zip(unique, counts))\n",
        "    for key in dic:\n",
        "      if key not in main:\n",
        "        main[key]=[resistance[i]]\n",
        "      else:\n",
        "        main[key].append(resistance[i])\n",
        "print(main.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU2-IMY8pkel"
      },
      "source": [
        "# Here we will only predict the sequences that are classified as 'Virulence' in the main discriminator.\n",
        "if len(virulence)!=0:\n",
        "  virulence_model = keras.models.load_model('ADD THE PATH HERE FOR THE TRAINED VIRULENCE MODEL') # Add here the path for the virulence model. We provided a trained model in the repository.\n",
        "\n",
        "  prediction = virulence_model.predict(np.asarray(virulence))   # [Adhesion, Toxin]\n",
        "  Preds = prediction.copy()\n",
        "  Preds[ np.where( Preds >= 0.5 ) ] = 1 \n",
        "  Preds[ np.where( Preds < 0.5 ) ] = 0\n",
        "\n",
        "  adhesion=[]\n",
        "  Toxin=[]\n",
        "  for i in range(len(Preds)):\n",
        "    if Preds[i][0]==1:\n",
        "      adhesion.append(virulence[i])\n",
        "    if Preds[i][1]==1:\n",
        "      Toxin.append(virulence[i])\n",
        "  print('\\n----------------------------------------------------------------')\n",
        "  print('Number of adhesion mechanism sequences found: ' + str(len(adhesion)))\n",
        "  print('Number of toxin mechanism sequences found: ' + str(len(Toxin)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iks56ChRpyVj"
      },
      "source": [
        "# Here we will only predict the sequences that are classified as 'Virulence' in the main discriminator.\n",
        "if len(promiscuity)!=0:\n",
        "  promiscuity_pad = pad_sequences(np.asarray(promiscuity), maxlen=3066, padding='post', truncating='post', value=0)\n",
        "  promiscuity_model = keras.models.load_model('ADD THE PATH HERE FOR THE TRAINED PROMISCUITY MODEL') # Add here the path for the promiscuity model. We provided a trained model in the repository.\n",
        "\n",
        "  prediction = promiscuity_model.predict(promiscuity_pad)   \n",
        "  Preds = prediction.copy()\n",
        "  Preds[ np.where( Preds >= 0.5 ) ] = 1\n",
        "  Preds[ np.where( Preds < 0.5 ) ] = 0\n",
        "\n",
        "  transformation=[]\n",
        "  conjugation=[]\n",
        "\n",
        "  for i in range(len(Preds)):\n",
        "    if Preds[i][0]==1:\n",
        "      conjugation.append(promiscuity[i])\n",
        "    if Preds[i][1]==1:\n",
        "      transformation.append(promiscuity[i])\n",
        "\n",
        "  print('\\n----------------------------------------------------------------')\n",
        "  print('Number of conjugation mechanism sequences found: ' + str(len(conjugation)))\n",
        "  print('Number of transformation mechanism sequences found: ' + str(len(transformation)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBDQc1gbkcf_"
      },
      "source": [
        "## **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF60lCBKsI3v"
      },
      "source": [
        "The results obtained for the input sequences are shown here. On the one hand, information about each of the sequences classified in each class is displayed in the notebook. Then, two different CSV files are generated. The first is organized into two columns: one for a RGB sequences asigned depending on the prediction (which will be used in other steps of the process) and the second one is the sequence itself. We call this CSV as the 'Colour CSV'. Finally, the second CSV contains a column with the predicted class and one with each sequence. We call this CSV as the 'Label CSV'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYxNnSubkeX5"
      },
      "source": [
        "print('-------------------NUMBER OF RESISTANCE SEQUENCES-------------------')\n",
        "print('nº: '+str(len(resistance)))\n",
        "\n",
        "if len(resistance)!=0:\n",
        "  ct=0\n",
        "  Aminoglycosides=[]\n",
        "  betalactams=[]\n",
        "  Glycopeptides=[]\n",
        "  Rifampin=[]\n",
        "  MLS =[]\n",
        "  Tetracyclines=[]\n",
        "  Sulfonamides=[]\n",
        "  Lipopeptides=[]\n",
        "  Phenicol=[]\n",
        "  for i in main:\n",
        "    print('--- '+str(i)+' ---')\n",
        "    print('nº: ',len(main[i]))\n",
        "    print('-----------------------------' +'\\n')\n",
        "    for j in main[i]:\n",
        "      ct+=1\n",
        "      gene=''\n",
        "      for k in j:\n",
        "        if k !=0:\n",
        "          gene=gene+(list(word_index.keys())[list(word_index.values()).index(k)])\n",
        "      print('gene nº '+str(ct) +': '+gene +'\\n')\n",
        "      if i=='Aminoglycosides':\n",
        "        Aminoglycosides.append(gene)\n",
        "      elif i=='betalactams':\n",
        "        betalactams.append(gene)\n",
        "      elif i=='Glycopeptides':\n",
        "        Glycopeptides.append(gene)\n",
        "      elif i=='Rifampin':\n",
        "        Rifampin.append(gene)\n",
        "      elif i=='MLS':\n",
        "        MLS.append(gene)\n",
        "      elif i=='Tetracyclines':\n",
        "        Tetracyclines.append(gene)\n",
        "      elif i=='Sulfonamides':\n",
        "        Sulfonamides.append(gene)\n",
        "      elif i=='Lipopeptides':\n",
        "        Lipopeptides.append(gene)\n",
        "      elif i=='Phenicol':\n",
        "        Phenicol.append(gene)\n",
        "    print('\\n')\n",
        "print('-------------------NUMBER OF VIRULENCE SEQUENCES-------------------')\n",
        "print('nº: '+str(len(virulence)))\n",
        "\n",
        "if len(virulence)!=0:\n",
        "  ct=0\n",
        "  print('--- Toxins ---')\n",
        "  print('nº: ',len(Toxin))\n",
        "  print('-----------------------------' +'\\n')\n",
        "  toxin_decoded=[]\n",
        "  for i in Toxin:\n",
        "    ct+=1\n",
        "    gene=''\n",
        "    for k in i:\n",
        "      if k !=0:\n",
        "        gene=gene+(list(word_index.keys())[list(word_index.values()).index(k)])\n",
        "    toxin_decoded.append(gene)\n",
        "    print('gene nº '+str(ct) +': '+gene +'\\n')\n",
        "  print('\\n')\n",
        "  print('--- Adhesion ---')\n",
        "  print('nº: ',len(adhesion))\n",
        "  print('-----------------------------' +'\\n')\n",
        "  ct=0\n",
        "  adhesion_decoded=[]\n",
        "  for i in adhesion:\n",
        "    ct+=1\n",
        "    gene=''\n",
        "    for k in i:\n",
        "      if k !=0:\n",
        "        gene=gene+(list(word_index.keys())[list(word_index.values()).index(k)])\n",
        "    adhesion_decoded.append(gene)\n",
        "    print('gene nº '+str(ct) +': '+gene +'\\n')\n",
        "\n",
        "print('-------------------NUMBER OF PROMISCUITY SEQUENCES-------------------')\n",
        "print('nº: '+str(len(promiscuity)))\n",
        "\n",
        "if len(promiscuity)!=0:\n",
        "  ct=0\n",
        "  print('--- Conjugation ---')\n",
        "  print('nº: ',len(conjugation))\n",
        "  print('-----------------------------' +'\\n')\n",
        "  conjugation_decoded=[]\n",
        "  for i in conjugation:\n",
        "    ct+=1\n",
        "    gene=''\n",
        "    for k in i:\n",
        "      if k !=0:\n",
        "        gene=gene+(list(word_index.keys())[list(word_index.values()).index(k)])\n",
        "    conjugation_decoded.append(gene)\n",
        "    print('gene nº '+str(ct) +': '+gene +'\\n')\n",
        "  print('\\n')\n",
        "  print('--- Transformation ---')\n",
        "  print('nº: ',len(transformation))\n",
        "  print('-----------------------------' +'\\n')\n",
        "  ct=0\n",
        "  transformation_decoded=[]\n",
        "  for i in transformation:\n",
        "    ct+=1\n",
        "    gene=''\n",
        "    for k in i:\n",
        "      if k !=0:\n",
        "        gene=gene+(list(word_index.keys())[list(word_index.values()).index(k)])\n",
        "    transformation_decoded.append(gene)\n",
        "    print('gene nº '+str(ct) +': '+gene +'\\n')\n",
        "    \n",
        "if nodanger!=0:\n",
        "  nodanger_decoded=[]\n",
        "  for i in nodanger:\n",
        "    gene=''\n",
        "    for k in i:\n",
        "      if k !=0:\n",
        "        gene=gene+(list(word_index.keys())[list(word_index.values()).index(k)])\n",
        "    nodanger_decoded.append(gene)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIOheNg561Cg"
      },
      "source": [
        "results = open('ADD HERE THE PATH FOR WRITING THE COLOUR CSV','w')\n",
        "results.write('Prediction,Genes''\\n')\n",
        "results2 = open('ADD HERE THE PATH FOR WRITING THE LABEL CSV','w')\n",
        "results2.write('Prediction,Genes''\\n')\n",
        "\n",
        "c,f=2,len(gene_decoded)\n",
        "Matrix=[[0 for i in range(c)] for j in range(f)]\n",
        "Matrix2=[[0 for i in range(c)] for j in range(f)]\n",
        "for i in range(len(gene_decoded)):\n",
        "  Matrix[i][1]=gene_decoded[i]\n",
        "  if gene_decoded[i] in Aminoglycosides:\n",
        "    Matrix[i][0]='[128.128.128]'\n",
        "    Matrix2[i][0]='Aminoglycosides'\n",
        "  elif gene_decoded[i] in betalactams:\n",
        "    Matrix[i][0]='[255.255.0]'\n",
        "    Matrix2[i][0]='betalactams'\n",
        "  elif gene_decoded[i] in Glycopeptides:\n",
        "    Matrix[i][0]='[128.255.0]'\n",
        "    Matrix2[i][0]='Glycopeptides'\n",
        "  elif gene_decoded[i] in Rifampin:\n",
        "    Matrix[i][0]='[0.255.0]'\n",
        "    Matrix2[i][0]='Rifampin'\n",
        "  elif gene_decoded[i] in MLS:\n",
        "    Matrix[i][0]='[0.255.128]'\n",
        "    Matrix2[i][0]='MLS'\n",
        "  elif gene_decoded[i] in Tetracyclines:\n",
        "    Matrix[i][0]='[0.255.255]'\n",
        "    Matrix2[i][0]='Tetracyclines'\n",
        "  elif gene_decoded[i] in Sulfonamides:\n",
        "    Matrix[i][0]='[0.128.255]'\n",
        "    Matrix2[i][0]='Sulfonamides'\n",
        "  elif gene_decoded[i] in Lipopeptides:\n",
        "    Matrix[i][0]='[0.0.255]'\n",
        "    Matrix2[i][0]='Lipopeptides'\n",
        "  elif gene_decoded[i] in Phenicol:\n",
        "    Matrix[i][0]='[127.0.255]'\n",
        "    Matrix2[i][0]='Phenicol'\n",
        "  elif gene_decoded[i] in toxin_decoded:\n",
        "    Matrix[i][0]='[255.0.255]'\n",
        "    Matrix2[i][0]='Toxin'\n",
        "  elif gene_decoded[i] in adhesion_decoded:\n",
        "    Matrix[i][0]='[255.0.127]'\n",
        "    Matrix2[i][0]='Adhesion'\n",
        "  elif gene_decoded[i] in conjugation_decoded:\n",
        "    Matrix[i][0]='[255.0.0]'\n",
        "    Matrix2[i][0]='Conjugation'\n",
        "  elif gene_decoded[i] in transformation_decoded:\n",
        "    Matrix[i][0]='[255.128.0]'\n",
        "    Matrix2[i][0]='Transformation'\n",
        "  else:\n",
        "    Matrix[i][0]='[0.0.0]'\n",
        "    Matrix2[i][0]='Misclassification'\n",
        "\n",
        "\n",
        "for i in Matrix:\n",
        "  results.write(str(i[0])+','+str(i[1])+'\\n')\n",
        "results.close()\n",
        "for i in Matrix2:\n",
        "  results2.write(str(i[0])+','+str(i[1])+'\\n')\n",
        "results2.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}